<html>


<head>
<title>Haskell Exchange Bytes October 2016</title>

<link rel="stylesheet" href="highlight.js/styles/default.css">
<script src="highlight.js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<link rel="stylesheet" href="Slidy2/styles/slidy.css" type="text/css" />
<script src="Slidy2/scripts/slidy.js" charset="utf-8" type="text/javascript"></script> 
</head>

<body>

<div class="slide">
<h1>start</h1>
<ul>
<li>Ben Clifford</li>
<li>benc@hawaga.org.uk</li>
<li><a href="https://www.instagram.com/beautifuldestinations/">BeautifulDestinations</a></li>

</div>
<div class="slide">
<h1>Introduction</h1>
<p>
Beautiful Destinations - we're doing a lot of data science on images. Not the
subject of this talk.
</p>
<p>Three loosely coupled sections:</p>
<ul>
 <li>shake</li>
 <li>ghc/ghcjs</li>
 <li>postgres database subsetting</li>
</ul>

</div>

<div class="slide">
<h1>1. Shake</h1>

<p>Shake is a library for building build systems, in Haskell - not a
commandline tool called <code>shake</code></p>
<p>Build systems build your code - <code>stack</code> is a simple
example, for Haskell code only</p>
<p>Shake build systems are not limited to Haskell... In our case:
<ul>
  <li>Haskell code in GHC/GHCJS</li>
  <li>css/javascript processing</li>
  <li>Debian packages</li>
  <li>Docker images containing our basic environments</li>
  <li>Docker images containing our Python analytics components</li>
</ul>
</div>

<div class="slide">
<h1>Two uses of shake</h1>
<ul>
 <li>the small one</li>
 <li>the big one</li>
</ul>
</div>

<div class="slide">
<h1>Small use of shake: Before</h1>

<p>Makefile based build system</p>
<p>Make likes things to be very file oriented: here
is <code>a.o</code>, build it from <code>a.c</code>.
<p>Or, targets that always run - when you can't
express dependencies as files.</p>
</div>
<div class="slide">
<h1>Small use of shake: Before</h1>
<pre><code class="makefile">
frontpack: frontbuild
        (cd $(JSDIR) && rm -f hash_*)
        (cd $(JSDIR) && cat rts.js lib.js out.js > all.js)
        (cd $(JSDIR) && ccjs all.js --warning_level=QUIET \
          --compilation_level=SIMPLE_OPTIMIZATIONS  > all.min.js)
        (cd $(JSDIR) && zopfli -i10 all.min.js)
        (find public/platform/ -name '*.css' -exec cat {} \; \
           > $(JSDIR)/all.css)
        (cd $(JSDIR) && zopfli -i10 all.css)
        $(eval JSHASH := $(shell cd $(JSDIR) && md5sum all.min.js.gz | cut -c1-16))
        echo $(JSDIR)
        ls $(JSDIR)
        echo JSHASH=$(JSHASH)
        (cd $(JSDIR) && cp all.min.js.gz hash_$(JSHASH).js.gz)
        (cd $(JSDIR) && cp all.min.js hash_$(JSHASH).js)
</code>
</pre>
</div>
<div class="slide">
<h1>Small use of shake: Before</h1>
<p>What can't we express?</p>
<p>This depends on all of the css files, and also depends on
   which CSS files exist: if either changes, need to rebuild.
<pre><code class="makefile">(find public/platform/ -name '*.css' -exec cat {} \; \
           > $(JSDIR)/all.css)
</code>
</pre>
</p>
<p>And because <code>all.css</code> is always rebuilt, expensive post-processing
must always happen:
<pre><code class="makefile"> (cd $(JSDIR) && zopfli -i10 all.css)</code></pre>
<p>Maybe shake can help?</p>
</div>

<div class="slide">
<h1>Small use of Shake: Now</h1>
<p>Makefile builds and calls a shake program:</p>
<pre><code class="makefile">frontpack: frontbuild
        (cd $(JSDIR) && rm -fv hash_*)
        stack build shake
        stack exec -- runhaskell shake/BuildMinified.hs -j2 --jsdir=$(JSDIR) ${SHAKEOPTS}
        $(eval JSHASH := $(shell cd $(JSDIR) && md5sum all.min.js.gz | cut -c1-16))
        echo $(JSDIR)
        ls $(JSDIR)
        echo JSHASH=$(JSHASH)
        (cd $(JSDIR) && cp all.min.js.gz hash_$(JSHASH).js.gz)
        (cd $(JSDIR) && cp all.min.js hash_$(JSHASH).js)
</code>
</pre>
</div>

<div class="slide">
<h1><code>BuildMinified.hs</code>: top level</h1>
<pre><code class="haskell">want
         [ jsdir &lt;/> "all.css"
         , jsdir &lt;/> "all.css.gz"
         , jsdir &lt;/> "all.min.js"
         , jsdir &lt;/> "all.min.js.gz"
         ]

"//*.min.js" %> minify
"//*.gz" %> compress
-- NO DEPENDENCIES WRITTEN HERE!

(jsdir &lt;/> "all.js") %> combineJS jsdir
(jsdir &lt;/> "all.css") %> combineCSS jsdir 
-- OR HERE!
</code></pre></div>

<div class="slide">
<h1><code>BuildMinified.hs</code>: helper functions</h1>
<pre><code class="haskell">combineCSS jsdir outFilename = do
  let cssDir = "public/platform"
  cssFiles <- getDirectoryFiles cssDir ["//*.css"] -- DEPENDENCY ON DIRECTORY
  let fullCssFiles = (cssDir </>) <$> cssFiles
  need fullCssFiles -- DEPENDENCY ON GENERATED LIST OF FILES
  combineFiles fullCssFiles outFilename

compress compressedFilename = do
  let uncompressedFilename = compressedFilename -<.> ""
  need [uncompressedFilename] -- DEPENDENCY ON FILE (LIKE make)
  f <- isFast -- DEPENDENCY ON COMMANDLINE FLAG (ORACLE)
  if f
    then cmd $ "gzip --keep --force -1 " ++ uncompressedFilename
    else cmd $ "zopfli -i10 " ++ uncompressedFilename
</code>
</pre>
</div>

<div class="slide">
<h1>Bigger shake: Buildosaurus</h1>
<p>Build "everything"</p>
<p>Collection of end products and intermediate
stages that build them: docker images for building,
docker images for deployment, debian packages,
and test cases.
</p>
<p>Before:</p>
<p>Lots of ad-hoc scripts spread in tooling
git repository and in CI system.</p>
<p>Lots of weird bodges/secret knowledge: what tools
to run in which order; tooling bug workarounds</p>
<p>And then we got a junior sysadmin and it was time
for me to explain how it all fitted together...</p>
</div>

<div class="slide">
<h1>Bigger shake: Buildosaurus</h1>
<p>Rather than explain everything to new sysadmin
or write it down in prose which would rot,
write the instructions in machine readable form.
</p>
<p><code>buildosaurus</code> - a shake-based
program which knows how to build all of our software
starting at a clean Linux+docker install and a git checkout.
</p>
</div>

<div class="slide">
<h1>Buildosaurus: Payoffs</h1>
<ul>
<li>devs can more easily build ~production system, which
they never did before</li>
<li>Version control of build system - as part of move to
monorepo</li>
<li>Take Haskell functions to do useful build steps and
repurpose - eg "give me a disposable database" command</li>
<li>Our build bodges+niggles are written down: the bodges aren't
fixed but they are described.
</div>

<div class="slide">
<h1>Buildosaurus: implementation</h1>
<ul>
<li>stack-based project: multiple source files, can use hackage libraries</li>
<li>Co-ordinate existing tools for building and
packaging: stack, docker, dpkg. Not
re-implementing their existing dependency and
caching behaviour.
</li>
</ul>
</div>

<div class="slide">
<h1>Buildosaurus: oracles</h1>
<p>Oracles allow builds to depend on extra information</p>
<p>Commandline flag in small use case</p>
<pre><code class="haskell">addOracle getFilteredDirectoryContentsOracle
addOracle alwaysValidateDockerImageOracle
addOracle getCommitIDOracle
</code></pre>
</div>

<div class="slide">
<h1>Buildosaurus: getCommitIDOracle</h1>
<p>This lets us depend on the git commit ID of the current
   checkout, which might change even though relevant files don't.</p>

<pre><code class="haskell">
getCommitIDOracle :: GetCommitID -> Action GitCommitID
getCommitIDOracle (GetCommitID ()) = do
  cmdfile <- getTempFilename
  writeCmdFile cmdfile [
      "#!/bin/bash"
    , "git rev-parse HEAD"
    ]

  (Stdout commit_id') <- cmd cmdfile
  let commit_id = stripString commit_id'
  return commit_id
</code></pre>
</div>

<div class="slide">
<h1>Test certifications</h1>
<ul>
<li>Track which test suites have run as build artefacts - the
output of a test suite is a certification that the
test suite ran (actually just an empty file ~ <code>()</code>)</li>
<li>Know which test suites need re-running - regular build
dependencies - rather than running all tests every time</li>
<li>Can depend on things other than source files easily:
eg test data files, git version.
</li>
</div>


<div class="slide">
<h1>shake: downsides</h1>
<ul>

<li>sysadmins have to learn "some" Haskell</li>

<li>enough changes happening in shake that I still want to
    pay attention to 'master' vs recent releases.
</li>

<li>need more infrastructure in place (eg stack)
    to build, which is a bit of a chicken-and-egg
    situation because I want buildosaurus to be
    managing things like that.
</li>

<li>simple stuff feels much more verbose.
   (but complex stuff feels much simpler / actually
    expressable)</li>
</pre>

</div>
<div class="slide">
<pre>

  catch all the bodges that we needed - eg not able to share
    ~/.stack,ghc,ghcjs between two of our components so we
    have to reroute; and makefile isn't expressive enough to
    give single-target builds.
    but now we have a codified place to describe those bodges
     and work on them rather than it being folklore about
      "oh delete your ~/.stack"

   TODO: a graph of all the components. parallelise with 
    modern shake so we can see parallelism? clean build on
    fresh AWS machine so no pollution

  using caches from  other tools: docker cache, .stack cache
    - these have different semantics - eg docker is content
        based, and can cope with multiple versons in cache at
       once, where shake's build directory approach is
         "either you have the current version or its invalid
          and we must rebuild". stack is slightly opaque and
         misbehaving sometimes.
    - don't get to control those so much. (downside)

</pre>
</div>

<div class="slide">
<h1>2. ghcjs vs ghc</h1>

<ul>
<li>Overall good experience but rough round edges</li>
<li>Shared source code between frontend (in browser) and backend (on server)</li>
<li>... but we've endedup with a lot of <code>#ifdef</code> ickiness</li>
</ul>
</div>
<div class="slide">
<h1>The good: Shared source code</h1>
<ul>
<li>Mostly shared data structures: representing our
domain objects but also queries/commands</li>
<li>Version this as a single application version
(aka git commit ID) running in a distributed setting.</li>
<li>
Data structures shared between frontend and backend
only need to work within that same version - that
is type checked, like other data passed around inside
an application</li>
<li>Communication between halves is HTTP GET/POST + JSON,
but that is not
fundamental: most JSON is done by generics and
we can probably replace that straightforwardly with
any other internal serialisation protocol</li>

</div>

<div class="slide">
<h1>The bad: Rough edges</h1>
<ul>
<li>We run our own patched ghcjs, for Template Haskell
performance. It was unusably slow. <a href="https://github.com/ghcjs/ghcjs/issues/449">#449</a></li>
<li>stack vs ghcjs doesn't version shared state correctly. Workaround in
buildosaurus using Docker magic. <a href="https://github.com/commercialhaskell/stack/issues/2365">#2365</a></li>
<li>Some days I seem to spend my whole day compiling ghcjs over and over</li>
</ul>
</div>


<div class="slide">
<h1>The Ugly: the <code>#ifdef</code> monster</h1>

<p>Our <code>lib/</code> is riddled with
<code>#ifdef</code>.</p>

</div>

<div class="slide">
<h1>Cross platform string types: Text vs JSString</h1>

<pre><code class="haskell">
data Account = Account
  { id              :: AccountId
  , username        :: Text
  } deriving Generic, FromJSON, ToJSON
</code>
</pre>
but...
<pre><code class="haskell">
#ifndef __GHCJS__
import Data.Text (Text)
#else
type Text = JSString
#endif
</code>
</pre>
</div>

<div class="slide">
<h1>The Ugly: the <code>#ifdef</code> monster</h1>
<ul>
<li>Text and other types: Int vs Integer, postgres
structures that leak</li>
<li>Poor simulation of files/modules/separate libraries
    for historical reasons: eg no postgres, so #ifdef
    away anything that talks about postgres on the
    frontend side.</li>
</ul>
</div>
<div class="slide">
<h1>The WTF</h1>
<ul>
<li><code>cabal configure</code> for ghcjs runs in JavaScript.</li>
<li>So in node.js (as does Template Haskell)
<li>To call shell commands for preprocessing use ghcjs FFI from node.js</li>

<pre><code class="haskell">
#ifdef __GHCJS__
import GHCJS.Types (JSString)
import Data.JSString (pack)

foreign import javascript unsafe "var e = require('child_process').execSync;
                                  var cmd = 'cpp -P < ' + $1 + ' > ' + $2; e(cmd);"
  cpp :: JSString -> JSString -> IO ()

main = do
  cpp (pack "jsbits/fast-renderer.js") (pack "jsbits/fast-renderer.out.js")
  defaultMain
#endif

</code>
</pre>
</div>

<div class="slide">
<pre>

         - config/package language not expressive enough (see later)

  - all these ifdefs hark back to writing multiplatform C code when I started as developer
     - they're expressing a thing that the language (haskell or C) doesn't express well
       so we need a DSL on the front of that to generate haskell appropriate for our 
       platform.

  - build/deploy looks different for thge two platforms: in one we generate some exes and run them;
       in the other we generate a bunch of javascript which needs postprocessing and
       webserving. postprocessing, as mentioned in build system section, is a small piece of shake
</pre>

</div>
<div class="slide">
<h1>3. postgres-subset tool / database testing</h1>

<p>Wanted to do database testing in CI.</p>

<p>Haven't come across a tool that did what I wanted
(which surprised me a bit because I don't think it is
 that obscure)</p>

<pre>
 
 - initial driving goal: we want to have a small database in our
   CI that a run can mutate without affecting other CI stuff. (other approaches
   to this are "do some state changes, then tidy yourself up afterwards")

 - our big database takes on the order of 100G to store and hours to save/restore.
    (mostly some indexes) - that's too much for a CI run that we want to happen
    in minutes.

  - tool that didn't do what I want - take a big DB and
     output some subset of it that can be restored fast.
</pre>

</div>
<div class="slide">
<h1>The problem</h1>
<p>
Export a subset of tables based on some configuration. eg recent posts:
</p>

<pre><code class="sql">SELECT * FROM posts WHERE created_at > now() - interval '2 months'
</code></pre>

<p>... but other tables might use <code>posts</code> in a foreign key.</p>
<p>Can't export tables individually - where there is a foreign key, we
only export rows which are still valid given choices made in upstream tables.</p>

</div>

<div class="slide">
<h1>Fixpoints in SQL</h1>

<p>... but that isn't enough, because
tables can have foreign keys on themselves.</p>

<p>eg image table that represents "is thumbnail of" relation</p>

<p>Iterately shrink table until we reach a fixpoint.</p>

<p>SQL has <code><a href="https://www.postgresql.org/docs/9.6/static/queries-with.html">WITH RECURSIVE</a></code> which can find fixpoints when
expanding data, but not when shrinking data. So implemented iteration
in Haskell.</p>

<p>But even this might not be enough (it is for our database though)
because there might be a mutually recursive group of tables, that need
to be iteratively shrunk all together.</p>

</div>

<div class="slide">
<h1>use in testing</h1>
<ul>
<li>easy standup of throwaway (mutable) database with fairly
realistic data (because it is extracted from real data)
</li>
<li>
what do we need to configure? what parts highlight a "smell" in database
definition? (fake foreign keys? what aren't they defined in the schema?)</li>

<li>giving a different database to the
    app that is not the mega-production-app database. so it should work. but sometimes
    it doesn't. what was wrong? bug in schema definition again? bug in
    application code that is highlighted by being used against a slightly
    different but valid database? </li>

</ul>

</div>
<div class="slide">
<h1>bugs</h1>

<ul>

<li> time related bugs  - SQL clauses are mostly functional, but now() isn't.
      noticed at the point where we had lots of records created very rapidyly
      a month ago - so now() iterating was selecting a different subset every
      time. would have converged eventually. but maybe to 0 and maybe after
      running for a month...

       - pretty straightforward IO vs pure problem 
</li>

<li> race condition between tables being dumped 
      - again, shared state (the database) changing underneath us.
      - SQL has the isolation we need: transactions
</li>

<li> mutually recursive definitions - hopefully straightforward, when
       needed </li>

</div>

<div class="slide">
<h1>fin</h1>
</div>
</body>

</html>
